---
layout: post
title: "Cheating and School Surveillance"
date: 2020-10-06 21:00:00 +0000
image: https://s3.amazonaws.com/hackedu/2017-ed-tech-trends-8.jpg
imagecredits: https://www.flickr.com/photos/thomashawk/282668729
---
<p><em>I have volunteered to be a guest speaker in classes this Fall. It's really the least I can do to help teachers and students through another tough term. I spoke this morning to Jeffrey Austin's class at the Skyline Writing Center.</em></p>

<p>Thank you very much for inviting me to speak to you today. I am very fond of writing centers, as I taught writing — college composition to be exact — for a number of years when I was a graduate student at the University of Oregon. The state of Oregon requires two terms of composition for graduation, thus Writing 121 and 122 were courses that almost all students had to take. (You could test out of the former, but not the latter.) Many undergraduates dreaded the class, some procrastinating until they were juniors or seniors in taking it — something that defeated the point, in so many ways, of helping students become better writers of college essays. </p>

<p>The University of Oregon also required that the graduate students who mostly taught these classes take a year long training in composition theory and pedagogy. It’s still sort of shocking to me how many people receive their PhDs and go on to become professors without taking any classes in how to teach their discipline, but I digress…</p>

<p>I don’t recall spending much time talking about plagiarism as I learned how to teach writing — this was all over twenty years ago, so forgive me — although I am sure the topic came up. We were obligated, the professor who ran the writing department said, to notify her if we found a student had cheated. These were the days before TurnItIn and other plagiarism checking software were widely adopted by schools. (These were the early days of the learning management system software, however, and the UO was an early adopter of Blackboard — that's a different albeit related story.) If we suspected cheating, we had a couple of options. Google a sentence or two to see if the passage could be found online. Ask our colleagues if the argument sounded familiar. Confront the student.</p>

<p>I always found it pretty upsetting when I suspected a student had plagiarized a paper. I tried to structure my assignments in such a way to minimize it — asking students turn in a one word sentence describing their argument and then a draft so that I could see their thinking and writing take shape. I felt as though I’d not done enough to guide a student toward success when they turned to essay mills or friends to plagiarize. I wanted to support students, not police them. </p>

<p>When I talked to students about cheating, I found it was rarely a matter of not understanding how to properly cite their sources. Nor was it really a lazy attempt to get out of doing work. Rather, students were under pressure. They hated writing. They weren't confident they had anything substantive to say. They were struggling with other classes, with time management, with aspects of their lives outside of schooling — jobs, family, and so on. Students needed more support, not more surveillance, which as I find myself repeating a lot these days, is too often confused with care.</p>

<p>I never met a student who was a Snidely Whiplash of cheating, twisting his mustache and rubbing his hands together with glee as he displayed callous and wanton academic dishonesty.</p>

<p>But that’s how so much of the educational software that’s sold to schools to curb cheating seems to imagine students — all students: unrepentant criminals, who must be rooted out and punished. Guilty until TurnItIn proves you innocent. </p>

<p>Let me pause and say that, as I prepared these remarks, I weighed whether or not I wanted to extend the Snidely Whiplash reference and refer to anti-cheating software as the Dudley Do-Right of ed-tech — that bumbling, incompetent Mountie, who was somehow seen as the hero. But I don't really know how familiar you are with the cartoon Dudley Do-Right. And I don't want to upset any Canadians. </p>

<p>I will, however, say this: anti-cheating software, whether it’s plagiarism detection or test proctoring — is “cop shit.” And cops do not belong on school grounds.</p>

<p>I don't know much about your organization. I don't know how controversial those two sentences are: first, my claim that ed-tech is “cop shit,” and second, that police should be removed from schools. </p>

<p>Since the death of George Floyd this summer, the calls to eliminate school police have grown louder. It's been a decades-long fight, in fact, in certain communities, but some schools and districts, such as in Oakland where I live, have successfully started to defund and dismantle their forces. It's an important step towards racial justice in schools, because <a href="https://www.aclu.org/news/criminal-law-reform/police-in-schools-continue-to-target-black-brown-and-indigenous-students-with-disabilities-the-trump-administration-has-data-thats-likely-to-prove-it/">we know</a> that school police officers disproportionately target and arrest students with disabilities and students of color. Students of color are more likely to attend schools that are under-resourced, for example, without staff trained to respond to behavioral problems. They are more likely to attend a school with a police officer. Black students are twice as likely to be referred to law enforcement by schools as white students. Black girls are over eight times more likely to be arrested at school as white girls. During the 2015-2016 school year, some 1.6 million students attended a school with a cop but no counselor. Defunding the police then means reallocating resources so that every child can have access to a nurse, a counselor — to a person who cares.</p>

<p>But what does this have to do with ed-tech, you might be thinking…</p>

<p>In many ways, education technology merely reinscribes the beliefs and practices of the analog world. It's less a force of disruption than it is a force for the consolidation of power. So if we know that school discipline is racist and ableist, then it shouldn't surprise us that the software that gets built to digitize disciplinary practices is racist and ableist too. </p>

<p>Back in February, Jeffrey Moro, a PhD candidate in English at the University of Maryland, wrote a very astute blog post &quot;<a href="https://jeffreymoro.com/blog/2020-02-13-against-cop-shit/">Against Cop Shit</a>&quot; in the classroom.</p>

<p>&quot;For the purposes of this post,&quot; Moro wrote, &quot;I define 'cop shit' as 'any pedagogical technique or technology that presumes an adversarial relationship between students and teachers.' Here are some examples:</p>

<ul>
<li>ed-tech that tracks our students' every move</li>
<li>plagiarism detection software</li>
<li>militant tardy or absence policies, particularly ones that involve embarrassing our students, e.g. locking them out of the classroom after class has begun</li>
<li>assignments that require copying out honor code statements</li>
<li>'rigor,' 'grit,' and 'discipline'</li>
<li>any interface with actual cops, such as reporting students' immigration status to ICE and calling cops on students sitting in classrooms.</li>
</ul>

<p>The history of some of these practices is quite long. But I think that this particular moment that we're in right now has greatly raised the stakes with regards to the implications of &quot;cop shit&quot; in schools.</p>

<p><a href="http://hackeducation.com/2017/02/02/ed-tech-and-trump">In the very first talk I gave</a> during the Trump Administration — just 13 days after his inauguration — I warned of the potential for ed-tech to be used to target, monitor, and profile at-risk students, particularly undocumented and queer students. I didn't use the phrase &quot;cop shit,&quot; but I could clearly see how easy it would be for a strain of Trumpism to amplify the surveillance technologies that already permeated our schools. Then, in February 2017, I wanted to sound the alarm. Now, almost four years later, it's clear we need to do more than that. We need to dismantle the surveillance ed-tech that already permeates our schools. I think this is one of our most important challenges in the months and years ahead. We must abolish &quot;cop shit,&quot; recognizing that almost all of ed-tech is precisely that.</p>

<p>Why do we have so much &quot;cop shit&quot; in our classrooms, Jeffrey Moro asks in his essay. &quot;One provisional answer is that the people who sell cop shit are very good at selling cop shit,&quot; he writes, &quot;whether that cop shit takes the form of a learning management system or a new pedagogical technique. Like any product, cop shit claims to solve a problem. We might express that problem like this: the work of managing a classroom, at all its levels, is increasingly complex and fraught, full of poorly defined standards, distractions to our students' attentions, and new opportunities for grift. Cop shit, so cop shit argues, solves these problems by bringing order to the classroom. Cop shit defines parameters. Cop shit ensures compliance. Cop shit gives students and teachers alike instant feedback in the form of legible metrics.&quot;</p>

<p>Ed-tech didn't create the &quot;cop shit&quot; in the classroom or launch a culture of surveillance in schools by any means. But it has facilitated it. It has streamlined it. </p>

<p>People who work in ed-tech and with ed-tech have to take responsibility for this, and not just shrug and say it's inevitable or it's progress or school sucked already and it's not our fault. We have to take responsibility because we are facing a number of crises — some old and some new — that are going to require us to rethink how and why and if we monitor and control teachers and students — <em>which</em> teachers and students. Because now, the “cop shit&quot; that schools are being sold isn't just mobile apps that track whether you've completed your homework on time or that assess whether you cheated when you did it. Now we're talking about tracking body temperature. Contacts. Movement. And as I feared back in early 2017, gender identity. Immigration status. Political affiliation. </p>

<p>Surveillance in schools reflects the values that schools have (unfortunately) prioritized: control, compulsion, distrust, efficiency. Surveillance is necessary, or so we've been told, because students cheat, because students lie, because students fight, because students disobey, because students struggle. Much of the physical classroom layout, for example, is meant to heighten surveillance and diminish cheating opportunities: the teacher in a supervisory stance at the front of the class, wandering up and down the rows of desks and peering over the shoulders of students. (It's easier, I should note, to shift the chairs in your classroom around than it is to shift the code in your software.) And all of this surveillance, we know, plays out very differently for different students in different schools — which schools require schools to walk through metal detectors, which schools call the police for disciplinary infractions, which schools track what students do online, even when they're at home. And nowadays, <em>especially</em> when they're at home. </p>

<p>Last month, officials in Edgewater, Colorado called the cops on a 12 year old boy who held a toy gun during his Zoom class. He was suspended from school.</p>

<p>Digital technology companies like to say that they're increasingly handing over decision-making to algorithms — it's not that the principal called the cops; the algorithm did. Automation is part of the promise of surveillance ed-tech — that is, the automation of the work of disciplining, monitoring, grading. That way, education gets cheaper, faster, better. </p>

<p>We've seen lately, particularly with the switch to online learning, a push for the automation of cheating prevention. Proctoring software is some of the most outrageous &quot;cop shit&quot; in schools right now.</p>

<p>These tools gather and analyze far more data than just a student's responses on an exam. They require a student show photo identification to their laptop camera before the test begins. Depending on what kind of ID they use, the software gathers data like name, signature, address, phone number, driver’s license number, passport number, along with any other personal data on the ID. That might include citizenship status, national origin, or military status. The software also gathers physical characteristics or descriptive data including age, race, hair color, height, weight, gender, or gender expression. It then matches that data that to the student's &quot;biometric faceprint&quot; captured by the laptop camera. Some of these products also capture a student's keystrokes and keystroke patterns. Some ask for the student to hand over the password to their machine. Some track location data, pinpointing where the student is working. They capture audio and video from the session — the background sounds and scenery from a student's home. Some ask for a tour of the student's room to make sure there aren't &quot;suspicious items&quot; on the walls or nearby. </p>

<p>The proctoring software then uses this data to monitor a student's behavior during the exam and to identify patterns that it infers as cheating — if their eyes stray from the screen too long, for example. The algorithm — sometimes in concert with a human proctor — determines who is a cheat. But more chilling, I think, the algorithm decides who suspicious, what is suspicious. </p>

<p>We know that algorithms are biased, because we know that humans are biased. We know that facial recognition software struggles to identify people of color, for example, and there have been reports from students of color that the proctoring software has demanded they move into more well-lit rooms or shine more light on their faces during the exam. Because the algorithms that drive the decision-making in these products is proprietary and &quot;black-boxed,&quot; we don't know if or how it might use certain physical traits or cultural characteristics to determine suspicious behavior. </p>

<p>We know there is a long and racist history of physiognomy and phrenology that has attempted to predict people's moral character from their physical appearance. And we know that schools have a long and racist history too that runs adjacent to this, as do technology companies — and this is really important. We can see how the mistrust and loathing of students is part of a proctoring company culture and gets baked into a proctoring company's software when, for example, the CEO posts copies of a student's chat logs with customer service onto Reddit, <a href="https://www.theguardian.com/australia-news/2020/jul/01/ceo-of-exam-monitoring-software-proctorio-apologises-for-posting-students-chat-logs-on-reddit">as the head of Proctorio did last month</a>. (Proctorio is also suing an instructional technologist from British Columbia for sharing links to unlisted YouTube videos on Twitter.)</p>

<p>That, my friends, is some serious &quot;cop shit.&quot; If we believe that cops have no business in schools — and the research certainly supports that — then hopefully we can see that neither does Proctorio.</p>

<p>But even beyond that monstrous company, we have much to unwind within the culture and the practices of schools. We must move away from a culture of suspicion and towards one of trust. That will demand we rethink &quot;cheating&quot; and cheating prevention.</p>

<p>Indeed, I will close by saying that — as with so much in ed-tech — the actual tech itself may be a distraction from the conversation we should have about what we actually want teaching and learning to look like. We have to change the culture of schools not just adopt kinder ed-tech. We have to stop the policing of classrooms in all its forms and support other models for our digital and analog educational practices.</p>