---
layout: post
title: "Education Technology and <em>The Age of Surveillance Capitalism</em>"
date: 2019-08-28 23:37:00 +0000
image: https://s3.amazonaws.com/hackedu/2019-08-28-pigeon.jpg
imagecredits: https://www.flickr.com/photos/slyronit/14807863071
---
<p>The future of education is technological. Necessarily so. </p>

<p>Or that&#8217;s what the proponents of ed-tech would want you to believe. In order to prepare students for the future, the practices of teaching and learning &#8211; indeed the whole notion of &#8220;school&#8221; &#8211; must embrace tech-centered courseware and curriculum. Education must adopt not only the products but the values of the high tech industry. It must conform to the demands for efficiency, speed, scale. </p>

<p>To resist technology, therefore, is to undermine students&#8217; opportunities. To resist technology is to deny students&#8217; their future.</p>

<p>Or so the story goes.</p>

<p>Shoshana Zuboff weaves a very different tale in her book <em>The Age of Surveillance Capitalism</em>. Its subtitle, <em>The Fight for a Human Future at the New Frontier of Power</em>, underscores her argument that the acquiescence to new digital technologies is detrimental to our futures. These technologies foreclose rather than foster future possibilities.</p>

<p>And that sure seems plausible, what with our social media profiles being scrutinized to adjudicate our immigration status, our fitness trackers being monitored to determine our insurance rates, our reading and viewing habits being manipulated by black-box algorithms, our devices listening in and nudging us as the world seems to totter towards totalitarianism.</p>

<p>We have known for some time now that tech companies extract massive amounts of data from us in order to run (and ostensibly improve) their services. But increasingly, Zuboff contends, these companies are now using our data for much more than that: to shape and modify and predict our behavior &#8211; &#8220;&#8216;treatments&#8217; or &#8216;data pellets&#8217; that select good behaviors,&#8221; as one ed-tech executive described it to Zuboff. She calls this &#8220;behavioral surplus,&#8221; a concept that is fundamental to surveillance capitalism, which she argues is a new form of political, economic, and social power that has emerged from the &#8220;internet of everything.&#8221; </p>

<p>Zuboff draws in part on the work of B. F. Skinner to make her case &#8211; his work on behavioral modification of animals, obviously, but also his larger theories about behavioral and social engineering, best articulated perhaps in his novel <em>Walden Two</em> and in his most controversial book <em>Beyond Freedom and Dignity</em>. By shaping our behaviors &#8211; through nudges and rewards &#8220;data pellets&#8221; and the like &#8211; technologies circumscribe our ability to make decisions. They impede our &#8220;right to the future tense,&#8221; Zuboff contends.</p>

<p>Google and Facebook are paradigmatic here, and Zuboff argues that the former was instrumental in discovering the value of behavioral surplus when it began, circa 2003, using user data to fine-tune ad targeting and to make predictions about which ads users would click on. More clicks, of course, led to more revenue, and behavioral surplus became a new and dominant business model, at first for digital advertisers like Google and Facebook but shortly thereafter for all sorts of companies in all sorts of industries.</p>

<p>And that includes ed-tech, of course &#8211; most obviously in predictive analytics software that promises to identify struggling students (such as Civitas Learning) and in behavior management software that&#8217;s aimed at fostering &#8220;a positive school culture&#8221; (like ClassDojo). </p>

<p>Google and Facebook, whose executives are clearly the villains of Zuboff&#8217;s book, have keen interests in the education market too. The former is much more overt, no doubt, with its Google Suite product offerings and its ubiquitous corporate evangelism. But the latter shouldn&#8217;t be ignored, even if it&#8217;s seen as simply a consumer-facing product. Mark Zuckerberg is an active education technology investor; Facebook has &#8220;learning communities&#8221; called Facebook Education; and the company&#8217;s engineers helped to build the personalized learning platform for the charter school chain Summit Schools. The kinds of data extraction and behavioral modification that Zuboff identifies as central to surveillance capitalism are part of Google and Facebook&#8217;s education efforts, even if laws like COPPA prevent these firms from monetizing the products directly through advertising.</p>

<p>Despite these companies&#8217; influence in education, despite Zuboff&#8217;s reliance on B. F. Skinner&#8217;s behaviorist theories, and despite her insistence that surveillance capitalists are poised to dominate the future of work &#8211; not as a division of labor but as a division of <em>learning</em> &#8211; Zuboff has nothing much to say about how education technologies specifically might operate as a key lever in this new form of social and political power that she has identified. (The quotation above from the &#8220;data pellet&#8221; fellow notwithstanding.)</p>

<p>Of course, I never expect people to write about ed-tech, despite the importance of the field historically to the development of computing and Internet technologies or the theories underpinning them. (B. F. Skinner is certainly a case in point.) Intertwined with the notion that &#8220;the future of education is necessarily technological&#8221; is the idea that the past and present of education are utterly pre-industrial, and that digital technologies must be used to reshape education (and education technologies) &#8211; this rather than recognizing the long, long history of education technologies and the ways in which these have shaped what today&#8217;s <em>digital</em> technologies generally have become.</p>

<p>As Zuboff relates the history of surveillance capitalism, she contends that it constitutes a break from previous forms of capitalism (forms that Zuboff seems to suggest were actually quite benign). I don&#8217;t buy it. She claims she can pinpoint this break to a specific moment and a particular set of actors, positing that the origin of this new system was Google&#8217;s development of AdSense. She does describe a number of other factors at play in the early 2000s that led to the rise of surveillance capitalism: notably, a post&#8211;9/11 climate in which the US government was willing to overlook growing privacy concerns about digital technologies and to use them instead to surveil the population in order to predict and prevent terrorism. And there are other threads she traces as well: neoliberalism and the pressures to privatize public institutions and deregulate private ones; individualization and the demands (socially and economically) of consumerism; and behaviorism and Skinner&#8217;s theories of operant conditioning and social engineering. While Zuboff does talk at length about how we got here, the &#8220;here&#8221; of surveillance capitalism, she argues, is a radically new place with new markets and new socioeconomic arrangements:</p>

<blockquote>
<p>&#8230;[T]he competitive dynamics of these new markets drive surveillance capitalists to acquire ever-more-predictive sources of behavioral surplus: our voices, personalities, and emotions. Eventually, surveillance capitalists discovered that the most-predictive behavioral data come from intervening in the state of play in order to nudge, coax, tune, and herd behavior toward profitable outcomes. Competitive pressures produced this shift, in which automated machine processes not only know our behavior but also shape our behavior at scale. With this reorientation from knowledge to power, it is no longer enough to automate information flows about us; the goal now is to automate us. In this phase of surveillance capitalismâ€™s evolution, the means of production are subordinated to an increasingly complex and comprehensive &#8216;means of behavioral modification.&#8217; In this way, surveillance capitalism births a new species of power that I call instrumentarianism. Instrumentarian power knows and shapes human behavior toward others&#8217; ends. Instead of armaments and armies, it works its will through the automated medium of an increasingly ubiquitous computational architecture of &#8216;smart&#8217; networked devices, things, and spaces. </p>
</blockquote>

<p>As this passage indicates, Zuboff believes (but never states outright) that a Marxist analysis of capitalism is no longer sufficient. And this is incredibly important as it means, for example, that her framework does not address how <em>labor</em> has changed under surveillance capitalism. Because even with the centrality of data extraction and analysis to this new system, there <em>is</em> still work. There <em>are</em> still workers. There <em>is</em> still class and plenty of room for an analysis of class, digital work, and high tech consumerism. Labor &#8211; digital or otherwise &#8211; remains in conflict with capital. <em>The Age of Surveillance Capitalism</em> <a href="https://thebaffler.com/latest/capitalisms-new-clothes-morozov">as Evgeny Morozov&#8217;s lengthy review in <em>The Baffler</em> puts it</a>, might succeed as &#8220;a warning against &#8216;surveillance dataism,&#8217;&#8221; but largely fails as a theory of capitalism.</p>

<p>Yet the book, while ignoring education technology, might be at its most useful in helping further a criticism of education technology in just those terms: as surveillance technologies, relying on data extraction and behavior modification. (That&#8217;s not to say that education technology criticism shouldn&#8217;t develop a much more rigorous analysis of labor. Good grief.) </p>

<p>As Zuboff points out, B. F. Skinner &#8220;imagined a pervasive &#8216;technology of behavior&#8217;&#8221; that would transform all of society but that, at the very least he hoped, would transform education. Today&#8217;s corporations might be better equipped to deliver technologies of behavior at scale, but this was already a big business in the 1950s and 1960s. Skinner&#8217;s ideas did not only exist in the fantasy of <em>Walden Two</em>. Nor did they operate solely in the psych lab. Behavioral engineering was central to the development of teaching machines; and despite the story that somehow, after <a href="https://www.nybooks.com/articles/1971/12/30/the-case-against-bf-skinner/">Chomsky denounced Skinner in the pages of <em>The New York Review of Books</em></a>, that no one &#8220;did behaviorism&#8221; any longer, it remained integral to much of educational computing on into the 1970s and 1980s. </p>

<p>And on and on and on &#8211; a more solid through line than the all-of-a-suddenness that Zuboff narrates for the birth of surveillance capitalism. Personalized learning &#8211; the kind hyped these days by Mark Zuckerberg and many others in Silicon Valley &#8211; is just the latest version of Skinner&#8217;s behavioral technology. Personalized learning relies on data extraction and analysis; it urges and rewards students and promises everyone will reach &#8220;mastery.&#8221; It gives the illusion of freedom and autonomy perhaps &#8211; at least in its name; but personalized learning is fundamentally about conditioning and control. </p>

<p>&#8220;I suggest that we now face the moment in history,&#8221; Zuboff writes, &#8220;when the elemental <em>right to the future tense</em> is endangered by a panvasive digital architecture of behavior modification owned and operated by surveillance capital, necessitated by its economic imperatives, and driven by its laws of motion, all for the sake of its guaranteed outcomes.&#8221; I&#8217;m not so sure that surveillance capitalists are assured of guaranteed outcomes. The manipulation of platforms like Google and Facebook by white supremacists demonstrates that it&#8217;s not just the tech companies who are wielding this architecture to their own ends. </p>

<p>Nevertheless, those who work in and work with education technology need to confront and resist this architecture &#8211; the &#8220;surveillance dataism,&#8221; to borrow Morozov&#8217;s phrase &#8211; even if (especially if) the outcomes promised are purportedly &#8220;for the good of the student.&#8221;</p>